# NornicDB AMD64 CUDA + Heimdall (Cognitive Guardian)
# Self-contained build with local embedding AND Heimdall SLM support
#
# This image includes:
# - BGE-M3 embedding model for vector search
# - Qwen2.5-0.5B-Instruct (Q4_K_M) for Heimdall (cognitive database guardian)
#
# Build:
#   docker build -f docker/Dockerfile.amd64-cuda-heimdall -t timothyswt/nornicdb-amd64-cuda-bge-heimdall .
#
# Run:
#   docker run --gpus all -p 7474:7474 -p 7687:7687 -v nornicdb-data:/data timothyswt/nornicdb-amd64-cuda-bge-heimdall
#
# This is a "batteries included" deployment - no additional model downloads required.
# Heimdall provides: anomaly detection, runtime diagnosis, and memory curation via Bifrost chat.

ARG LLAMA_CUDA_IMAGE=timothyswt/llama-cuda-libs:b4785

# =============================================================================
# Stage 1: UI
# =============================================================================
FROM node:20-alpine AS ui
WORKDIR /ui
COPY ui/package*.json ./
RUN npm ci 2>/dev/null || npm install --legacy-peer-deps
COPY ui/ .
RUN npm run build

# =============================================================================
# Stage 2: Pre-built CUDA libs
# =============================================================================
FROM ${LLAMA_CUDA_IMAGE} AS llama

# =============================================================================
# Stage 3: Go build
# =============================================================================
FROM nvidia/cuda:12.6.3-devel-ubuntu22.04 AS builder

ENV GO_VERSION=1.25.5
RUN apt-get update && apt-get install -y wget git gcc g++ libgomp1 && \
    wget -q https://go.dev/dl/go${GO_VERSION}.linux-amd64.tar.gz && \
    tar -C /usr/local -xzf go${GO_VERSION}.linux-amd64.tar.gz && rm go*.tar.gz
ENV PATH="/usr/local/go/bin:${PATH}" CUDA_HOME=/usr/local/cuda

WORKDIR /build

# Copy llama artifacts
COPY --from=llama /output/lib/*.a /build/lib/llama/
COPY --from=llama /output/include/*.h /build/lib/llama/

# Go dependencies
COPY go.mod go.sum ./
RUN go mod download

# Source + UI
COPY . .
COPY --from=ui /ui/dist ./ui/dist

# Build with CUDA + localllm + heimdall
RUN echo "Building with CUDA + localllm + heimdall..." && \
    CGO_ENABLED=1 go build -tags "cuda localllm heimdall" \
      -ldflags="-s -w -X main.buildTime=$(date -u +%Y%m%d-%H%M%S)" \
      -o nornicdb ./cmd/nornicdb

# Build APOC plugin
RUN echo "Building APOC plugin..." && \
    mkdir -p apoc/built-plugins && \
    cd apoc/plugin-src/apoc && go build -buildmode=plugin -o ../../../apoc/built-plugins/apoc.so apoc_plugin.go && \
    echo "✓ Built plugin:" && ls -lh /build/apoc/built-plugins/*.so

# =============================================================================
# Stage 4: Runtime
# =============================================================================
FROM nvidia/cuda:12.6.3-runtime-ubuntu22.04
WORKDIR /app

RUN apt-get update && apt-get install -y --no-install-recommends \
    ca-certificates tzdata wget libgomp1 && rm -rf /var/lib/apt/lists/* && \
    mkdir -p /data /app/models

COPY --from=builder /build/nornicdb /app/
COPY --from=builder /build/apoc/built-plugins /app/plugins/
COPY docker/entrypoint.sh /app/
RUN chmod +x /app/entrypoint.sh

# Embed both models: BGE-M3 for embeddings + Qwen for Heimdall
RUN --mount=type=bind,source=models,target=/models,ro \
    echo "Embedding BGE-M3 model..." && \
    if [ -f /models/bge-m3.gguf ]; then \
      cp /models/bge-m3.gguf /app/models/ && \
      echo "✓ Embedded bge-m3.gguf ($(du -h /app/models/bge-m3.gguf | cut -f1))"; \
    else \
      echo "ERROR: models/bge-m3.gguf not found" && exit 1; \
    fi && \
    echo "Embedding Heimdall SLM model..." && \
    if [ -f /models/qwen2.5-0.5b-instruct-q4_k_m.gguf ]; then \
      cp /models/qwen2.5-0.5b-instruct-q4_k_m.gguf /app/models/ && \
      echo "✓ Embedded qwen2.5-0.5b-instruct-q4_k_m.gguf ($(du -h /app/models/qwen2.5-0.5b-instruct-q4_k_m.gguf | cut -f1))"; \
    else \
      echo "ERROR: models/qwen2.5-0.5b-instruct-q4_k_m.gguf not found" && exit 1; \
    fi && \
    echo "✓ Heimdall cognitive features enabled"

EXPOSE 7474 7687

HEALTHCHECK --interval=30s --timeout=10s --start-period=10s --retries=3 \
    CMD wget --spider -q http://localhost:7474/health || exit 1

ENV NORNICDB_DATA_DIR=/data \
    NORNICDB_HTTP_PORT=7474 \
    NORNICDB_BOLT_PORT=7687 \
    NORNICDB_EMBEDDING_PROVIDER=local \
    NORNICDB_EMBEDDING_MODEL=bge-m3 \
    NORNICDB_EMBEDDING_DIMENSIONS=1024 \
    NORNICDB_MODELS_DIR=/app/models \
    NORNICDB_EMBEDDING_GPU_LAYERS=-1 \
    NORNICDB_NO_AUTH=true \
    NORNICDB_GPU_ENABLED=true \
    NORNICDB_PLUGINS_DIR=/app/plugins \
    NORNICDB_HEIMDALL_ENABLED=true \
    NORNICDB_HEIMDALL_MODEL=qwen2.5-0.5b-instruct-q4_k_m \
    NVIDIA_VISIBLE_DEVICES=all \
    NVIDIA_DRIVER_CAPABILITIES=compute,utility \
    LD_LIBRARY_PATH=/usr/local/cuda/lib64:/usr/local/nvidia/lib64:${LD_LIBRARY_PATH}

ENTRYPOINT ["/app/entrypoint.sh"]
