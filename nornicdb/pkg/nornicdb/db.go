// Package nornicdb provides the main API for embedded NornicDB usage.
package nornicdb

import (
	"context"
	"crypto/rand"
	"encoding/hex"
	"encoding/json"
	"errors"
	"fmt"
	"sort"
	"sync"
	"time"

	"github.com/orneryd/nornicdb/pkg/cypher"
	"github.com/orneryd/nornicdb/pkg/decay"
	"github.com/orneryd/nornicdb/pkg/inference"
	"github.com/orneryd/nornicdb/pkg/search"
	"github.com/orneryd/nornicdb/pkg/storage"
)

// Errors returned by DB operations.
var (
	ErrNotFound     = errors.New("memory not found")
	ErrInvalidID    = errors.New("invalid memory ID")
	ErrClosed       = errors.New("database is closed")
	ErrInvalidInput = errors.New("invalid input")
)

// MemoryTier represents the decay tier of a memory.
type MemoryTier string

const (
	// TierEpisodic is for short-term memories (7-day half-life)
	TierEpisodic MemoryTier = "EPISODIC"
	// TierSemantic is for facts and concepts (69-day half-life)
	TierSemantic MemoryTier = "SEMANTIC"
	// TierProcedural is for skills and patterns (693-day half-life)
	TierProcedural MemoryTier = "PROCEDURAL"
)

// Memory represents a node in the knowledge graph.
type Memory struct {
	ID           string         `json:"id"`
	Content      string         `json:"content"`
	Title        string         `json:"title,omitempty"`
	Tier         MemoryTier     `json:"tier"`
	DecayScore   float64        `json:"decay_score"`
	CreatedAt    time.Time      `json:"created_at"`
	LastAccessed time.Time      `json:"last_accessed"`
	AccessCount  int64          `json:"access_count"`
	Embedding    []float32      `json:"embedding,omitempty"`
	Tags         []string       `json:"tags,omitempty"`
	Source       string         `json:"source,omitempty"`
	Properties   map[string]any `json:"properties,omitempty"`
}

// Edge represents a relationship between memories.
type Edge struct {
	ID            string         `json:"id"`
	SourceID      string         `json:"source_id"`
	TargetID      string         `json:"target_id"`
	Type          string         `json:"type"`
	Confidence    float64        `json:"confidence"`
	AutoGenerated bool           `json:"auto_generated"`
	Reason        string         `json:"reason,omitempty"`
	CreatedAt     time.Time      `json:"created_at"`
	Properties    map[string]any `json:"properties,omitempty"`
}

// Config holds NornicDB configuration.
type Config struct {
	// Storage
	DataDir string `yaml:"data_dir"`

	// Embeddings
	EmbeddingProvider   string `yaml:"embedding_provider"` // ollama, openai
	EmbeddingAPIURL     string `yaml:"embedding_api_url"`
	EmbeddingModel      string `yaml:"embedding_model"`
	EmbeddingDimensions int    `yaml:"embedding_dimensions"`

	// Decay
	DecayEnabled             bool          `yaml:"decay_enabled"`
	DecayRecalculateInterval time.Duration `yaml:"decay_recalculate_interval"`
	DecayArchiveThreshold    float64       `yaml:"decay_archive_threshold"`

	// Auto-linking
	AutoLinksEnabled             bool          `yaml:"auto_links_enabled"`
	AutoLinksSimilarityThreshold float64       `yaml:"auto_links_similarity_threshold"`
	AutoLinksCoAccessWindow      time.Duration `yaml:"auto_links_co_access_window"`

	// Server
	BoltPort int `yaml:"bolt_port"`
	HTTPPort int `yaml:"http_port"`
}

// DefaultConfig returns sensible default configuration.
func DefaultConfig() *Config {
	return &Config{
		DataDir:                      "./data",
		EmbeddingProvider:            "ollama",
		EmbeddingAPIURL:              "http://localhost:11434",
		EmbeddingModel:               "mxbai-embed-large",
		EmbeddingDimensions:          1024,
		DecayEnabled:                 true,
		DecayRecalculateInterval:     time.Hour,
		DecayArchiveThreshold:        0.05,
		AutoLinksEnabled:             true,
		AutoLinksSimilarityThreshold: 0.82,
		AutoLinksCoAccessWindow:      30 * time.Second,
		BoltPort:                     7687,
		HTTPPort:                     7474,
	}
}

// DB represents a NornicDB database instance.
type DB struct {
	config *Config
	mu     sync.RWMutex
	closed bool

	// Internal components
	storage        *storage.MemoryEngine
	decay          *decay.Manager
	inference      *inference.Engine
	cypherExecutor *cypher.StorageExecutor
	gpuManager     interface{} // *gpu.Manager - interface to avoid circular import
	
	// Search service (uses pre-computed embeddings from Mimir)
	searchService *search.Service
}

// Open opens or creates a NornicDB database.
func Open(dataDir string, config *Config) (*DB, error) {
	if config == nil {
		config = DefaultConfig()
	}
	config.DataDir = dataDir

	db := &DB{
		config: config,
	}

	// Initialize storage (in-memory for now, will add Badger later)
	db.storage = storage.NewMemoryEngine()

	// Initialize Cypher executor
	db.cypherExecutor = cypher.NewStorageExecutor(db.storage)

	// Initialize decay manager
	if config.DecayEnabled {
		decayConfig := &decay.Config{
			RecalculateInterval: config.DecayRecalculateInterval,
			ArchiveThreshold:    config.DecayArchiveThreshold,
			RecencyWeight:       0.4,
			FrequencyWeight:     0.3,
			ImportanceWeight:    0.3,
		}
		db.decay = decay.New(decayConfig)
	}

	// Initialize inference engine
	if config.AutoLinksEnabled {
		inferConfig := &inference.Config{
			SimilarityThreshold: config.AutoLinksSimilarityThreshold,
			SimilarityTopK:      10,
			CoAccessEnabled:     true,
			CoAccessWindow:      config.AutoLinksCoAccessWindow,
			CoAccessMinCount:    3,
			TransitiveEnabled:   true,
			TransitiveMinConf:   0.5,
		}
		db.inference = inference.New(inferConfig)
	}

	// Initialize search service (uses pre-computed embeddings from Mimir)
	db.searchService = search.NewService(db.storage)

	return db, nil
}

// LoadFromExport loads data from a Mimir JSON export directory.
// This loads nodes, relationships, and embeddings from the exported files.
func (db *DB) LoadFromExport(ctx context.Context, exportDir string) (*LoadResult, error) {
	db.mu.Lock()
	defer db.mu.Unlock()
	
	if db.closed {
		return nil, ErrClosed
	}
	
	// Use the storage loader
	result, err := storage.LoadFromMimirExport(db.storage, exportDir)
	if err != nil {
		return nil, fmt.Errorf("loading export: %w", err)
	}
	
	return &LoadResult{
		NodesLoaded:      result.NodesImported,
		EdgesLoaded:      result.EdgesImported,
		EmbeddingsLoaded: result.EmbeddingsLoaded,
	}, nil
}

// LoadResult holds the result of a data load operation.
type LoadResult struct {
	NodesLoaded      int `json:"nodes_loaded"`
	EdgesLoaded      int `json:"edges_loaded"`
	EmbeddingsLoaded int `json:"embeddings_loaded"`
}

// BuildSearchIndexes builds the search indexes from loaded data.
// Call this after loading data to enable search functionality.
func (db *DB) BuildSearchIndexes(ctx context.Context) error {
	db.mu.Lock()
	defer db.mu.Unlock()
	
	if db.closed {
		return ErrClosed
	}
	
	if db.searchService == nil {
		return fmt.Errorf("search service not initialized")
	}
	
	return db.searchService.BuildIndexes(ctx)
}

// Close closes the database.
func (db *DB) Close() error {
	db.mu.Lock()
	defer db.mu.Unlock()

	if db.closed {
		return nil
	}
	db.closed = true

	var errs []error

	if db.decay != nil {
		db.decay.Stop()
	}

	if db.storage != nil {
		if err := db.storage.Close(); err != nil {
			errs = append(errs, err)
		}
	}

	if len(errs) > 0 {
		return fmt.Errorf("close errors: %v", errs)
	}
	return nil
}

// Store creates a new memory with automatic relationship inference.
func (db *DB) Store(ctx context.Context, mem *Memory) (*Memory, error) {
	db.mu.Lock()
	defer db.mu.Unlock()

	if db.closed {
		return nil, ErrClosed
	}

	if mem == nil {
		return nil, ErrInvalidInput
	}

	// Set defaults
	if mem.ID == "" {
		mem.ID = generateID("mem")
	}
	if mem.Tier == "" {
		mem.Tier = TierSemantic
	}
	mem.DecayScore = 1.0
	now := time.Now()
	mem.CreatedAt = now
	mem.LastAccessed = now
	mem.AccessCount = 0

	// Convert to storage node
	node := memoryToNode(mem)

	// Store in storage engine
	if err := db.storage.CreateNode(node); err != nil {
		return nil, fmt.Errorf("storing memory: %w", err)
	}

	// Run auto-relationship inference if enabled
	if db.inference != nil && len(mem.Embedding) > 0 {
		suggestions, err := db.inference.OnStore(ctx, mem.ID, mem.Embedding)
		if err == nil {
			for _, suggestion := range suggestions {
				edge := &storage.Edge{
					ID:            storage.EdgeID(generateID("edge")),
					StartNode:     storage.NodeID(suggestion.SourceID),
					EndNode:       storage.NodeID(suggestion.TargetID),
					Type:          suggestion.Type,
					Confidence:    suggestion.Confidence,
					AutoGenerated: true,
					CreatedAt:     now,
					Properties: map[string]any{
						"reason": suggestion.Reason,
						"method": suggestion.Method,
					},
				}
				_ = db.storage.CreateEdge(edge) // Best effort
			}
		}
	}

	return mem, nil
}

// Remember performs semantic search for memories using embedding.
func (db *DB) Remember(ctx context.Context, embedding []float32, limit int) ([]*Memory, error) {
	db.mu.RLock()
	defer db.mu.RUnlock()

	if db.closed {
		return nil, ErrClosed
	}

	if len(embedding) == 0 {
		return nil, ErrInvalidInput
	}

	if limit <= 0 {
		limit = 10
	}

	// Get all nodes from storage (naive implementation for now)
	// TODO: Replace with HNSW index for efficient ANN search
	allNodes, err := db.storage.AllNodes()
	if err != nil {
		return nil, fmt.Errorf("getting nodes: %w", err)
	}

	type scored struct {
		mem   *Memory
		score float64
	}
	var results []scored

	for _, node := range allNodes {
		mem := nodeToMemory(node)
		if len(mem.Embedding) == 0 {
			continue
		}

		// Calculate cosine similarity
		sim := cosineSimilarity(embedding, mem.Embedding)
		results = append(results, scored{mem: mem, score: sim})
	}

	// Sort by similarity descending
	sort.Slice(results, func(i, j int) bool {
		return results[i].score > results[j].score
	})

	// Take top limit
	if len(results) > limit {
		results = results[:limit]
	}

	memories := make([]*Memory, len(results))
	for i, r := range results {
		memories[i] = r.mem
	}

	return memories, nil
}

// Recall retrieves a specific memory by ID and reinforces it.
func (db *DB) Recall(ctx context.Context, id string) (*Memory, error) {
	db.mu.Lock()
	defer db.mu.Unlock()

	if db.closed {
		return nil, ErrClosed
	}

	if id == "" {
		return nil, ErrInvalidID
	}

	// Get from storage
	node, err := db.storage.GetNode(storage.NodeID(id))
	if err != nil {
		return nil, ErrNotFound
	}

	mem := nodeToMemory(node)

	// Reinforce memory and update access patterns
	now := time.Now()

	if db.decay != nil {
		// Use decay manager to reinforce the memory
		info := &decay.MemoryInfo{
			ID:           mem.ID,
			Tier:         decay.Tier(mem.Tier),
			CreatedAt:    mem.CreatedAt,
			LastAccessed: mem.LastAccessed,
			AccessCount:  mem.AccessCount,
		}
		info = db.decay.Reinforce(info)
		mem.LastAccessed = info.LastAccessed
		mem.AccessCount = info.AccessCount
		mem.DecayScore = db.decay.CalculateScore(info)
	} else {
		mem.LastAccessed = now
		mem.AccessCount++
	}

	// Update storage
	node = memoryToNode(mem)
	if err := db.storage.UpdateNode(node); err != nil {
		return nil, fmt.Errorf("updating memory: %w", err)
	}

	// Track access for co-access inference
	if db.inference != nil {
		db.inference.OnAccess(ctx, mem.ID)
	}

	return mem, nil
}

// Cypher executes a Cypher query.
func (db *DB) Cypher(ctx context.Context, query string, params map[string]any) ([]map[string]any, error) {
	db.mu.RLock()
	defer db.mu.RUnlock()

	if db.closed {
		return nil, ErrClosed
	}

	// Execute query through Cypher executor
	result, err := db.cypherExecutor.Execute(ctx, query, params)
	if err != nil {
		return nil, err
	}

	// Convert to []map[string]any format
	results := make([]map[string]any, len(result.Rows))
	for i, row := range result.Rows {
		results[i] = make(map[string]any)
		for j, col := range result.Columns {
			if j < len(row) {
				results[i][col] = row[j]
			}
		}
	}

	return results, nil
}

// Link creates a relationship between two memories.
func (db *DB) Link(ctx context.Context, sourceID, targetID, edgeType string, confidence float64) (*Edge, error) {
	db.mu.Lock()
	defer db.mu.Unlock()

	if db.closed {
		return nil, ErrClosed
	}

	if sourceID == "" || targetID == "" {
		return nil, ErrInvalidID
	}

	if edgeType == "" {
		edgeType = "RELATES_TO"
	}

	if confidence <= 0 || confidence > 1 {
		confidence = 1.0
	}

	// Verify both nodes exist
	if _, err := db.storage.GetNode(storage.NodeID(sourceID)); err != nil {
		return nil, fmt.Errorf("source not found: %w", ErrNotFound)
	}
	if _, err := db.storage.GetNode(storage.NodeID(targetID)); err != nil {
		return nil, fmt.Errorf("target not found: %w", ErrNotFound)
	}

	now := time.Now()
	storageEdge := &storage.Edge{
		ID:            storage.EdgeID(generateID("edge")),
		StartNode:     storage.NodeID(sourceID),
		EndNode:       storage.NodeID(targetID),
		Type:          edgeType,
		Confidence:    confidence,
		AutoGenerated: false,
		CreatedAt:     now,
		Properties:    map[string]any{},
	}

	if err := db.storage.CreateEdge(storageEdge); err != nil {
		return nil, fmt.Errorf("creating edge: %w", err)
	}

	return storageEdgeToEdge(storageEdge), nil
}

// Neighbors returns memories connected to the given memory.
func (db *DB) Neighbors(ctx context.Context, id string, depth int, edgeType string) ([]*Memory, error) {
	db.mu.RLock()
	defer db.mu.RUnlock()

	if db.closed {
		return nil, ErrClosed
	}

	if id == "" {
		return nil, ErrInvalidID
	}

	if depth <= 0 {
		depth = 1
	}
	if depth > 5 {
		depth = 5 // Cap depth to prevent excessive traversal
	}

	// Helper to get all edges for a node
	getAllEdges := func(nodeID storage.NodeID) []*storage.Edge {
		var allEdges []*storage.Edge
		if out, err := db.storage.GetOutgoingEdges(nodeID); err == nil {
			allEdges = append(allEdges, out...)
		}
		if in, err := db.storage.GetIncomingEdges(nodeID); err == nil {
			allEdges = append(allEdges, in...)
		}
		return allEdges
	}

	// Collect neighbor IDs (BFS for depth > 1)
	visited := map[string]bool{id: true}
	currentLevel := []string{id}
	var neighborIDs []string

	for d := 0; d < depth; d++ {
		var nextLevel []string
		for _, nodeID := range currentLevel {
			nodeEdges := getAllEdges(storage.NodeID(nodeID))
			for _, edge := range nodeEdges {
				// Filter by edge type if specified
				if edgeType != "" && edge.Type != edgeType {
					continue
				}

				// Determine the "other" node
				var targetID string
				if string(edge.StartNode) == nodeID {
					targetID = string(edge.EndNode)
				} else {
					targetID = string(edge.StartNode)
				}

				if !visited[targetID] {
					visited[targetID] = true
					neighborIDs = append(neighborIDs, targetID)
					nextLevel = append(nextLevel, targetID)
				}
			}
		}
		currentLevel = nextLevel
	}

	// Fetch memory nodes
	var memories []*Memory
	for _, nid := range neighborIDs {
		node, err := db.storage.GetNode(storage.NodeID(nid))
		if err == nil {
			memories = append(memories, nodeToMemory(node))
		}
	}

	return memories, nil
}

// Forget removes a memory and its edges.
func (db *DB) Forget(ctx context.Context, id string) error {
	db.mu.Lock()
	defer db.mu.Unlock()

	if db.closed {
		return ErrClosed
	}

	if id == "" {
		return ErrInvalidID
	}

	// Check if memory exists
	if _, err := db.storage.GetNode(storage.NodeID(id)); err != nil {
		return ErrNotFound
	}

	// Delete the node (storage should handle edge cleanup)
	if err := db.storage.DeleteNode(storage.NodeID(id)); err != nil {
		return fmt.Errorf("deleting memory: %w", err)
	}

	return nil
}

// generateID creates a unique ID with prefix.
func generateID(prefix string) string {
	b := make([]byte, 8)
	_, _ = rand.Read(b)
	return prefix + "-" + hex.EncodeToString(b)
}

// memoryToNode converts a Memory to a storage.Node.
func memoryToNode(mem *Memory) *storage.Node {
	props := make(map[string]any)
	props["content"] = mem.Content
	props["title"] = mem.Title
	props["tier"] = string(mem.Tier)
	props["decay_score"] = mem.DecayScore
	props["last_accessed"] = mem.LastAccessed.Format(time.RFC3339)
	props["access_count"] = mem.AccessCount
	props["source"] = mem.Source
	props["tags"] = mem.Tags

	// Merge custom properties
	for k, v := range mem.Properties {
		props[k] = v
	}

	return &storage.Node{
		ID:         storage.NodeID(mem.ID),
		Labels:     []string{"Memory"},
		Properties: props,
		Embedding:  mem.Embedding,
		CreatedAt:  mem.CreatedAt,
	}
}

// nodeToMemory converts a storage.Node to a Memory.
func nodeToMemory(node *storage.Node) *Memory {
	mem := &Memory{
		ID:         string(node.ID),
		CreatedAt:  node.CreatedAt,
		Properties: make(map[string]any),
	}

	// Extract known properties
	if v, ok := node.Properties["content"].(string); ok {
		mem.Content = v
	}
	if v, ok := node.Properties["title"].(string); ok {
		mem.Title = v
	}
	if v, ok := node.Properties["tier"].(string); ok {
		mem.Tier = MemoryTier(v)
	}
	if v, ok := node.Properties["decay_score"].(float64); ok {
		mem.DecayScore = v
	}
	if v, ok := node.Properties["last_accessed"].(string); ok {
		if t, err := time.Parse(time.RFC3339, v); err == nil {
			mem.LastAccessed = t
		}
	}
	if v, ok := node.Properties["access_count"].(int64); ok {
		mem.AccessCount = v
	} else if v, ok := node.Properties["access_count"].(int); ok {
		mem.AccessCount = int64(v)
	}
	if v, ok := node.Properties["source"].(string); ok {
		mem.Source = v
	}
	if v, ok := node.Properties["tags"].([]string); ok {
		mem.Tags = v
	} else if v, ok := node.Properties["tags"].([]interface{}); ok {
		mem.Tags = make([]string, len(v))
		for i, tag := range v {
			mem.Tags[i], _ = tag.(string)
		}
	}

	// Copy embedding directly (both are []float32)
	if len(node.Embedding) > 0 {
		mem.Embedding = make([]float32, len(node.Embedding))
		copy(mem.Embedding, node.Embedding)
	}

	// Store remaining properties
	knownKeys := map[string]bool{
		"content": true, "title": true, "tier": true,
		"decay_score": true, "last_accessed": true,
		"access_count": true, "source": true, "tags": true,
	}
	for k, v := range node.Properties {
		if !knownKeys[k] {
			mem.Properties[k] = v
		}
	}

	return mem
}

// edgeToEdge converts storage.Edge to nornicdb.Edge.
func storageEdgeToEdge(se *storage.Edge) *Edge {
	e := &Edge{
		ID:            string(se.ID),
		SourceID:      string(se.StartNode),
		TargetID:      string(se.EndNode),
		Type:          se.Type,
		Confidence:    se.Confidence,
		AutoGenerated: se.AutoGenerated,
		CreatedAt:     se.CreatedAt,
		Properties:    se.Properties,
	}
	if v, ok := se.Properties["reason"].(string); ok {
		e.Reason = v
	}
	return e
}

// cosineSimilarity computes cosine similarity between two float32 vectors.
func cosineSimilarity(a, b []float32) float64 {
	if len(a) != len(b) || len(a) == 0 {
		return 0
	}

	var dot, normA, normB float64
	for i := 0; i < len(a); i++ {
		aFloat := float64(a[i])
		bFloat := float64(b[i])
		dot += aFloat * bFloat
		normA += aFloat * aFloat
		normB += bFloat * bFloat
	}

	if normA == 0 || normB == 0 {
		return 0
	}

	return dot / (sqrt(normA) * sqrt(normB))
}

// sqrt is a simple square root implementation.
func sqrt(x float64) float64 {
	if x <= 0 {
		return 0
	}
	z := x / 2
	for i := 0; i < 10; i++ {
		z = z - (z*z-x)/(2*z)
	}
	return z
}

// =============================================================================
// HTTP Server Interface Methods
// =============================================================================

// Stats returns database statistics.
type DBStats struct {
	NodeCount int64 `json:"node_count"`
	EdgeCount int64 `json:"edge_count"`
	// Removed TransactionCount - was never incremented (always 0)
	// NornicDB uses thread-safe maps with RWMutex, not ACID transactions
}

// Stats returns current database statistics.
func (db *DB) Stats() DBStats {
	db.mu.RLock()
	defer db.mu.RUnlock()

	stats := DBStats{}
	if db.storage != nil {
		nodeCount, _ := db.storage.NodeCount()
		edgeCount, _ := db.storage.EdgeCount()
		stats.NodeCount = nodeCount
		stats.EdgeCount = edgeCount
	}
	return stats
}

// SetGPUManager sets the GPU manager for vector search acceleration.
// Uses interface{} to avoid circular import with gpu package.
func (db *DB) SetGPUManager(manager interface{}) {
	db.mu.Lock()
	defer db.mu.Unlock()
	db.gpuManager = manager
}

// GetGPUManager returns the GPU manager if set.
// Returns interface{} - caller must type assert to *gpu.Manager.
func (db *DB) GetGPUManager() interface{} {
	db.mu.RLock()
	defer db.mu.RUnlock()
	return db.gpuManager
}

// CypherResult holds results from a Cypher query.
type CypherResult struct {
	Columns []string        `json:"columns"`
	Rows    [][]interface{} `json:"rows"`
}

// ExecuteCypher runs a Cypher query and returns structured results.
func (db *DB) ExecuteCypher(ctx context.Context, query string, params map[string]interface{}) (*CypherResult, error) {
	db.mu.RLock()
	defer db.mu.RUnlock()

	if db.closed {
		return nil, ErrClosed
	}

	// Execute query through Cypher executor
	result, err := db.cypherExecutor.Execute(ctx, query, params)
	if err != nil {
		return nil, err
	}

	return &CypherResult{
		Columns: result.Columns,
		Rows:    result.Rows,
	}, nil
}

// Node represents a graph node for HTTP API.
type Node struct {
	ID         string                 `json:"id"`
	Labels     []string               `json:"labels"`
	Properties map[string]interface{} `json:"properties"`
	CreatedAt  time.Time              `json:"created_at"`
}

// ListNodes returns nodes with optional label filter.
func (db *DB) ListNodes(ctx context.Context, label string, limit, offset int) ([]*Node, error) {
	db.mu.RLock()
	defer db.mu.RUnlock()

	if db.closed {
		return nil, ErrClosed
	}

	allNodes, err := db.storage.AllNodes()
	if err != nil {
		return nil, err
	}

	var nodes []*Node
	count := 0
	for _, n := range allNodes {
		// Filter by label if specified
		if label != "" {
			hasLabel := false
			for _, l := range n.Labels {
				if l == label {
					hasLabel = true
					break
				}
			}
			if !hasLabel {
				continue
			}
		}

		// Handle offset
		if count < offset {
			count++
			continue
		}

		// Handle limit
		if len(nodes) >= limit {
			break
		}

		nodes = append(nodes, &Node{
			ID:         string(n.ID),
			Labels:     n.Labels,
			Properties: n.Properties,
			CreatedAt:  n.CreatedAt,
		})
		count++
	}

	return nodes, nil
}

// GetNode retrieves a node by ID.
func (db *DB) GetNode(ctx context.Context, id string) (*Node, error) {
	db.mu.RLock()
	defer db.mu.RUnlock()

	if db.closed {
		return nil, ErrClosed
	}

	n, err := db.storage.GetNode(storage.NodeID(id))
	if err != nil {
		return nil, ErrNotFound
	}

	return &Node{
		ID:         string(n.ID),
		Labels:     n.Labels,
		Properties: n.Properties,
		CreatedAt:  n.CreatedAt,
	}, nil
}

// CreateNode creates a new node.
func (db *DB) CreateNode(ctx context.Context, labels []string, properties map[string]interface{}) (*Node, error) {
	db.mu.Lock()
	defer db.mu.Unlock()

	if db.closed {
		return nil, ErrClosed
	}

	id := generateID("node")
	now := time.Now()

	node := &storage.Node{
		ID:         storage.NodeID(id),
		Labels:     labels,
		Properties: properties,
		CreatedAt:  now,
	}

	if err := db.storage.CreateNode(node); err != nil {
		return nil, err
	}

	// Update search indexes (live indexing for seamless Mimir compatibility)
	if db.searchService != nil {
		_ = db.searchService.IndexNode(node) // Best effort - search may lag behind writes
	}

	return &Node{
		ID:         id,
		Labels:     labels,
		Properties: properties,
		CreatedAt:  now,
	}, nil
}

// UpdateNode updates a node's properties.
func (db *DB) UpdateNode(ctx context.Context, id string, properties map[string]interface{}) (*Node, error) {
	db.mu.Lock()
	defer db.mu.Unlock()

	if db.closed {
		return nil, ErrClosed
	}

	n, err := db.storage.GetNode(storage.NodeID(id))
	if err != nil {
		return nil, ErrNotFound
	}

	// Merge properties
	for k, v := range properties {
		n.Properties[k] = v
	}

	if err := db.storage.UpdateNode(n); err != nil {
		return nil, err
	}

	return &Node{
		ID:         string(n.ID),
		Labels:     n.Labels,
		Properties: n.Properties,
		CreatedAt:  n.CreatedAt,
	}, nil
}

// DeleteNode deletes a node.
func (db *DB) DeleteNode(ctx context.Context, id string) error {
	db.mu.Lock()
	defer db.mu.Unlock()

	if db.closed {
		return ErrClosed
	}

	return db.storage.DeleteNode(storage.NodeID(id))
}

// GraphEdge represents an edge for HTTP API.
type GraphEdge struct {
	ID         string                 `json:"id"`
	Source     string                 `json:"source"`
	Target     string                 `json:"target"`
	Type       string                 `json:"type"`
	Properties map[string]interface{} `json:"properties,omitempty"`
	CreatedAt  time.Time              `json:"created_at"`
}

// ListEdges returns edges with optional type filter.
func (db *DB) ListEdges(ctx context.Context, relType string, limit, offset int) ([]*GraphEdge, error) {
	db.mu.RLock()
	defer db.mu.RUnlock()

	if db.closed {
		return nil, ErrClosed
	}

	allEdges, err := db.storage.AllEdges()
	if err != nil {
		return nil, err
	}

	var edges []*GraphEdge
	count := 0
	for _, e := range allEdges {
		// Filter by type if specified
		if relType != "" && e.Type != relType {
			continue
		}

		// Handle offset
		if count < offset {
			count++
			continue
		}

		// Handle limit
		if len(edges) >= limit {
			break
		}

		edges = append(edges, &GraphEdge{
			ID:         string(e.ID),
			Source:     string(e.StartNode),
			Target:     string(e.EndNode),
			Type:       e.Type,
			Properties: e.Properties,
			CreatedAt:  e.CreatedAt,
		})
		count++
	}

	return edges, nil
}

// GetEdge retrieves an edge by ID.
func (db *DB) GetEdge(ctx context.Context, id string) (*GraphEdge, error) {
	db.mu.RLock()
	defer db.mu.RUnlock()

	if db.closed {
		return nil, ErrClosed
	}

	e, err := db.storage.GetEdge(storage.EdgeID(id))
	if err != nil {
		return nil, ErrNotFound
	}

	return &GraphEdge{
		ID:         string(e.ID),
		Source:     string(e.StartNode),
		Target:     string(e.EndNode),
		Type:       e.Type,
		Properties: e.Properties,
		CreatedAt:  e.CreatedAt,
	}, nil
}

// CreateEdge creates a new edge.
func (db *DB) CreateEdge(ctx context.Context, source, target, edgeType string, properties map[string]interface{}) (*GraphEdge, error) {
	db.mu.Lock()
	defer db.mu.Unlock()

	if db.closed {
		return nil, ErrClosed
	}

	// Verify nodes exist
	if _, err := db.storage.GetNode(storage.NodeID(source)); err != nil {
		return nil, fmt.Errorf("source node not found")
	}
	if _, err := db.storage.GetNode(storage.NodeID(target)); err != nil {
		return nil, fmt.Errorf("target node not found")
	}

	id := generateID("edge")
	now := time.Now()

	edge := &storage.Edge{
		ID:         storage.EdgeID(id),
		StartNode:  storage.NodeID(source),
		EndNode:    storage.NodeID(target),
		Type:       edgeType,
		Properties: properties,
		CreatedAt:  now,
	}

	if err := db.storage.CreateEdge(edge); err != nil {
		return nil, err
	}

	return &GraphEdge{
		ID:         id,
		Source:     source,
		Target:     target,
		Type:       edgeType,
		Properties: properties,
		CreatedAt:  now,
	}, nil
}

// DeleteEdge deletes an edge.
func (db *DB) DeleteEdge(ctx context.Context, id string) error {
	db.mu.Lock()
	defer db.mu.Unlock()

	if db.closed {
		return ErrClosed
	}

	return db.storage.DeleteEdge(storage.EdgeID(id))
}

// SearchResult holds a search result with score.
type SearchResult struct {
	Node  *Node   `json:"node"`
	Score float64 `json:"score"`
	
	// RRF metadata
	RRFScore   float64 `json:"rrf_score,omitempty"`
	VectorRank int     `json:"vector_rank,omitempty"`
	BM25Rank   int     `json:"bm25_rank,omitempty"`
}

// Search performs full-text BM25 search.
// For hybrid vector+text search, use HybridSearch with pre-computed query embedding.
func (db *DB) Search(ctx context.Context, query string, labels []string, limit int) ([]*SearchResult, error) {
	db.mu.RLock()
	defer db.mu.RUnlock()

	if db.closed {
		return nil, ErrClosed
	}

	if db.searchService == nil {
		return nil, fmt.Errorf("search service not initialized")
	}

	// Get adaptive search options based on query
	opts := search.GetAdaptiveRRFConfig(query)
	opts.Limit = limit
	if len(labels) > 0 {
		opts.Types = labels
	}

	// Full-text search only (no embedding generation)
	// For hybrid search, Mimir should call VectorSearch with pre-computed embedding
	response, err := db.searchService.Search(ctx, query, nil, opts)
	if err != nil {
		return nil, err
	}

	// Convert search results to our format
	results := make([]*SearchResult, len(response.Results))
	for i, r := range response.Results {
		results[i] = &SearchResult{
			Node: &Node{
				ID:         r.ID,
				Labels:     r.Labels,
				Properties: r.Properties,
			},
			Score:      r.Score,
			RRFScore:   r.RRFScore,
			VectorRank: r.VectorRank,
			BM25Rank:   r.BM25Rank,
		}
	}

	return results, nil
}

// HybridSearch performs RRF hybrid search combining vector similarity and BM25 full-text.
// The queryEmbedding should be pre-computed by Mimir using its embedding service.
// This is the primary search method for semantic search with ranking fusion.
func (db *DB) HybridSearch(ctx context.Context, query string, queryEmbedding []float32, labels []string, limit int) ([]*SearchResult, error) {
	db.mu.RLock()
	defer db.mu.RUnlock()

	if db.closed {
		return nil, ErrClosed
	}

	if db.searchService == nil {
		return nil, fmt.Errorf("search service not initialized")
	}

	// Get adaptive search options based on query
	opts := search.GetAdaptiveRRFConfig(query)
	opts.Limit = limit
	if len(labels) > 0 {
		opts.Types = labels
	}

	// Execute RRF hybrid search with Mimir's pre-computed embedding
	response, err := db.searchService.Search(ctx, query, queryEmbedding, opts)
	if err != nil {
		return nil, err
	}

	// Convert search results to our format
	results := make([]*SearchResult, len(response.Results))
	for i, r := range response.Results {
		results[i] = &SearchResult{
			Node: &Node{
				ID:         r.ID,
				Labels:     r.Labels,
				Properties: r.Properties,
			},
			Score:      r.Score,
			RRFScore:   r.RRFScore,
			VectorRank: r.VectorRank,
			BM25Rank:   r.BM25Rank,
		}
	}

	return results, nil
}

// FindSimilar finds nodes similar to a given node by embedding.
func (db *DB) FindSimilar(ctx context.Context, nodeID string, limit int) ([]*SearchResult, error) {
	db.mu.RLock()
	defer db.mu.RUnlock()

	if db.closed {
		return nil, ErrClosed
	}

	// Get target node
	target, err := db.storage.GetNode(storage.NodeID(nodeID))
	if err != nil {
		return nil, ErrNotFound
	}

	if len(target.Embedding) == 0 {
		return nil, fmt.Errorf("node has no embedding")
	}

	// Find similar by embedding
	allNodes, err := db.storage.AllNodes()
	if err != nil {
		return nil, err
	}

	type scored struct {
		node  *storage.Node
		score float64
	}
	var results []scored

	for _, n := range allNodes {
		if string(n.ID) == nodeID || len(n.Embedding) == 0 {
			continue
		}

		sim := cosineSimilarity(target.Embedding, n.Embedding)
		results = append(results, scored{node: n, score: sim})
	}

	// Sort by similarity
	sort.Slice(results, func(i, j int) bool {
		return results[i].score > results[j].score
	})

	if len(results) > limit {
		results = results[:limit]
	}

	searchResults := make([]*SearchResult, len(results))
	for i, r := range results {
		searchResults[i] = &SearchResult{
			Node: &Node{
				ID:         string(r.node.ID),
				Labels:     r.node.Labels,
				Properties: r.node.Properties,
				CreatedAt:  r.node.CreatedAt,
			},
			Score: r.score,
		}
	}

	return searchResults, nil
}

// GetLabels returns all distinct node labels.
func (db *DB) GetLabels(ctx context.Context) ([]string, error) {
	db.mu.RLock()
	defer db.mu.RUnlock()

	if db.closed {
		return nil, ErrClosed
	}

	allNodes, err := db.storage.AllNodes()
	if err != nil {
		return nil, err
	}

	labelSet := make(map[string]bool)
	for _, n := range allNodes {
		for _, l := range n.Labels {
			labelSet[l] = true
		}
	}

	labels := make([]string, 0, len(labelSet))
	for l := range labelSet {
		labels = append(labels, l)
	}
	sort.Strings(labels)

	return labels, nil
}

// GetRelationshipTypes returns all distinct edge types.
func (db *DB) GetRelationshipTypes(ctx context.Context) ([]string, error) {
	db.mu.RLock()
	defer db.mu.RUnlock()

	if db.closed {
		return nil, ErrClosed
	}

	allEdges, err := db.storage.AllEdges()
	if err != nil {
		return nil, err
	}

	typeSet := make(map[string]bool)
	for _, e := range allEdges {
		typeSet[e.Type] = true
	}

	types := make([]string, 0, len(typeSet))
	for t := range typeSet {
		types = append(types, t)
	}
	sort.Strings(types)

	return types, nil
}

// IndexInfo holds index metadata.
type IndexInfo struct {
	Name     string `json:"name"`
	Label    string `json:"label"`
	Property string `json:"property"`
	Type     string `json:"type"` // btree, fulltext, vector
}

// GetIndexes returns all indexes.
func (db *DB) GetIndexes(ctx context.Context) ([]*IndexInfo, error) {
	// TODO: Implement index management
	return []*IndexInfo{}, nil
}

// CreateIndex creates a new index.
func (db *DB) CreateIndex(ctx context.Context, label, property, indexType string) error {
	// TODO: Implement index management
	return nil
}

// Backup creates a database backup.
func (db *DB) Backup(ctx context.Context, path string) error {
	// TODO: Implement backup
	return nil
}

// ExportUserData exports all data for a user (GDPR compliance).
func (db *DB) ExportUserData(ctx context.Context, userID, format string) ([]byte, error) {
	db.mu.RLock()
	defer db.mu.RUnlock()

	if db.closed {
		return nil, ErrClosed
	}

	// Find all nodes associated with user
	allNodes, err := db.storage.AllNodes()
	if err != nil {
		return nil, err
	}

	var userData []map[string]interface{}
	for _, n := range allNodes {
		// Check if node belongs to user (by owner_id property or similar)
		if owner, ok := n.Properties["owner_id"].(string); ok && owner == userID {
			userData = append(userData, map[string]interface{}{
				"id":         string(n.ID),
				"labels":     n.Labels,
				"properties": n.Properties,
				"created_at": n.CreatedAt,
			})
		}
	}

	// Format output
	if format == "csv" {
		// TODO: Implement CSV export
		return []byte("id,labels,properties\n"), nil
	}

	// Default to JSON
	return json.Marshal(map[string]interface{}{
		"user_id":     userID,
		"data":        userData,
		"exported_at": time.Now(),
	})
}

// DeleteUserData deletes all data for a user (GDPR compliance).
func (db *DB) DeleteUserData(ctx context.Context, userID string) error {
	db.mu.Lock()
	defer db.mu.Unlock()

	if db.closed {
		return ErrClosed
	}

	allNodes, err := db.storage.AllNodes()
	if err != nil {
		return err
	}

	for _, n := range allNodes {
		if owner, ok := n.Properties["owner_id"].(string); ok && owner == userID {
			if err := db.storage.DeleteNode(n.ID); err != nil {
				return err
			}
		}
	}

	return nil
}

// AnonymizeUserData anonymizes all data for a user (GDPR compliance).
func (db *DB) AnonymizeUserData(ctx context.Context, userID string) error {
	db.mu.Lock()
	defer db.mu.Unlock()

	if db.closed {
		return ErrClosed
	}

	allNodes, err := db.storage.AllNodes()
	if err != nil {
		return err
	}

	anonymousID := "anon-" + generateID("")

	for _, n := range allNodes {
		if owner, ok := n.Properties["owner_id"].(string); ok && owner == userID {
			// Replace identifying info
			n.Properties["owner_id"] = anonymousID
			delete(n.Properties, "email")
			delete(n.Properties, "name")
			delete(n.Properties, "username")
			delete(n.Properties, "ip_address")

			if err := db.storage.UpdateNode(n); err != nil {
				return err
			}
		}
	}

	return nil
}
