# Mimir MCP Server Environment Configuration
# Copy this file to .env and customize as needed

# ============================================================================
# Database Configuration
# ============================================================================
NEO4J_PASSWORD=password
NEO4J_URI=bolt://localhost:7687
NEO4J_USER=neo4j

# ============================================================================
# Docker Configuration
# ============================================================================

# Host workspace directory to mount in container
# Default: ~/src (your home directory's src folder)
HOST_WORKSPACE_ROOT=~/src

# ============================================================================
# Ollama Configuration
# ============================================================================

# Ollama API endpoint
# - Local host: http://localhost:11434
# - Docker container: http://ollama:11434
OLLAMA_BASE_URL=http://localhost:11434

# ============================================================================
# Feature Flags
# ============================================================================

# Enable PM agent to suggest alternative models based on task requirements
# Default: false
MIMIR_FEATURE_PM_MODEL_SUGGESTIONS=false

# Enable vector embeddings and semantic search
# Requires Ollama with embedding model (e.g., nomic-embed-text)
# Default: false
MIMIR_FEATURE_VECTOR_EMBEDDINGS=false

# ============================================================================
# Embeddings Configuration (only used if VECTOR_EMBEDDINGS=true)
# ============================================================================

# Enable generation of embeddings during file indexing
# Must be true to use vector search
MIMIR_EMBEDDINGS_ENABLED=false

# Ollama embedding model to use
# Options: nomic-embed-text (recommended), mxbai-embed-large, all-minilm
# Run: ollama pull <model-name>
MIMIR_EMBEDDINGS_MODEL=nomic-embed-text

# Vector dimensions (model-specific)
# nomic-embed-text: 768
# mxbai-embed-large: 1024
# all-minilm: 384
MIMIR_EMBEDDINGS_DIMENSIONS=768

# Text chunking for large files (in tokens)
MIMIR_EMBEDDINGS_CHUNK_SIZE=512
MIMIR_EMBEDDINGS_CHUNK_OVERLAP=50

# ============================================================================
# Server Configuration
# ============================================================================

# Node environment (development | production)
NODE_ENV=production

# HTTP server port (if using HTTP transport)
PORT=3000

# File watching configuration
FILE_WATCH_POLLING=true
FILE_WATCH_INTERVAL=1000
WORKSPACE_ROOT=/workspace
MIMIR_PARALLEL_EXECUTION=true
MIMIR_ENABLE_ECKO=true