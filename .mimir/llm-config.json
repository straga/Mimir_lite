{
  "defaultProvider": "copilot",
  "providers": {
    "copilot": {
      "baseUrl": "http://localhost:4141/v1",
      "defaultModel": "gpt-4.1",
      "models": {
        "gpt-4.1": {
          "name": "gpt-4.1",
          "contextWindow": 128000,
          "description": "GitHub Copilot GPT-4 model via copilot-api proxy",
          "recommendedFor": ["pm", "worker", "qc"],
          "config": {
            "temperature": 0.0
          }
        }
      }
    },
    "ollama": {
      "baseUrl": "http://192.168.1.167:11434",
      "defaultModel": "deepseek-r1:14b",
      "models": {
        "mistral-nemo:12b": {
          "name": "mistral-nemo:12b",
          "contextWindow": 128000,
          "description": "Mistral Nemo 12B - high quality model with large context",
          "recommendedFor": ["pm", "worker", "qc"],
          "supportsTools": true,
          "config": {
            "numCtx": 128000,
            "temperature": 0.0,
            "numPredict": -1
          }
        },
        "deepseek-r1:14b": {
          "name": "deepseek-r1:14b",
          "contextWindow": 131072,
          "description": "DeepSeek R1 14B - reasoning-focused model",
          "recommendedFor": ["pm", "qc"],
          "supportsTools": false,
          "config": {
            "numCtx": 131072,
            "temperature": 0.0,
            "numPredict": -1
          }
        },
        "deepseek-r1:8b": {
          "name": "deepseek-r1:8b",
          "contextWindow": 131072,
          "description": "DeepSeek R1 8B - faster reasoning model",
          "recommendedFor": ["worker", "qc"],
          "supportsTools": false,
          "config": {
            "numCtx": 131072,
            "temperature": 0.0,
            "numPredict": -1
          }
        },
        "qwen2.5-coder:14b": {
          "name": "qwen2.5-coder:14b",
          "contextWindow": 262144,
          "description": "Qwen 2.5 Coder 14B - specialized coding model",
          "recommendedFor": ["worker"],
          "supportsTools": true,
          "config": {
            "numCtx": 262144,
            "temperature": 0.0,
            "numPredict": -1
          }
        },
        "deepcoder:14b": {
          "name": "deepcoder:14b",
          "contextWindow": 131072,
          "description": "DeepCoder 14B - coding-focused model",
          "recommendedFor": ["worker"],
          "supportsTools": false,
          "config": {
            "numCtx": 131072,
            "temperature": 0.0,
            "numPredict": -1
          }
        },
        "deepseek-coder:6.7b": {
          "name": "deepseek-coder:6.7b",
          "contextWindow": 16384,
          "description": "DeepSeek Coder 6.7B - compact coding model (NO TOOL SUPPORT)",
          "recommendedFor": ["worker", "testing"],
          "supportsTools": false,
          "config": {
            "numCtx": 16384,
            "temperature": 0.0,
            "numPredict": -1
          },
          "warnings": ["This model does not support tool calling"]
        },
        "deepseek-coder-v2:16b": {
          "name": "deepseek-coder-v2:16b",
          "contextWindow": 131072,
          "description": "DeepSeek Coder V2 16B - advanced coding model (NO TOOL SUPPORT)",
          "recommendedFor": ["worker"],
          "supportsTools": false,
          "config": {
            "numCtx": 131072,
            "temperature": 0.0,
            "numPredict": -1
          },
          "warnings": ["This model does not support tool calling"]
        },
        "qwen2.5-coder:1.5b-base": {
          "name": "qwen2.5-coder:1.5b-base",
          "contextWindow": 8192,
          "description": "Qwen 2.5 Coder 1.5B Base - tiny coding model for testing",
          "recommendedFor": ["testing"],
          "supportsTools": false,
          "config": {
            "numCtx": 8192,
            "temperature": 0.1,
            "numPredict": 1000
          }
        },
        "qwen3-coder:latest": {
          "name": "qwen3-coder:latest",
          "contextWindow": 262144,
          "description": "Qwen 3 Coder (30.5B MoE) - large coding model",
          "recommendedFor": ["pm", "worker"],
          "supportsTools": true,
          "config": {
            "numCtx": 262144,
            "temperature": 0.0,
            "numPredict": -1
          }
        },
        "sskostyaev/virtuoso-small:q6_k_l": {
          "name": "sskostyaev/virtuoso-small:q6_k_l",
          "contextWindow": 131072,
          "description": "Virtuoso Small 14.8B Q6_K - high quality quantization",
          "recommendedFor": ["worker"],
          "supportsTools": true,
          "config": {
            "numCtx": 131072,
            "temperature": 0.0,
            "numPredict": -1
          }
        },
        "phi4:14b": {
          "name": "phi4:14b",
          "contextWindow": 16384,
          "description": "Phi-4 14B - Microsoft's efficient model",
          "recommendedFor": ["worker", "qc"],
          "supportsTools": false,
          "config": {
            "numCtx": 16384,
            "temperature": 0.0,
            "numPredict": -1
          }
        },
        "phi4-reasoning:14b": {
          "name": "phi4-reasoning:14b",
          "contextWindow": 16384,
          "description": "Phi-4 Reasoning 14B - reasoning variant",
          "recommendedFor": ["pm", "qc"],
          "supportsTools": false,
          "config": {
            "numCtx": 16384,
            "temperature": 0.0,
            "numPredict": -1
          }
        },
        "qwen3:14b": {
          "name": "qwen3:14b",
          "contextWindow": 262144,
          "description": "Qwen 3 14B - general purpose model",
          "recommendedFor": ["pm", "worker"],
          "supportsTools": true,
          "config": {
            "numCtx": 262144,
            "temperature": 0.0,
            "numPredict": -1
          }
        },
        "qwen3:8b": {
          "name": "qwen3:8b",
          "contextWindow": 262144,
          "description": "Qwen 3 8B - balanced speed/quality",
          "recommendedFor": ["worker"],
          "supportsTools": true,
          "config": {
            "numCtx": 262144,
            "temperature": 0.0,
            "numPredict": -1
          }
        },
        "gemma3:12b": {
          "name": "gemma3:12b",
          "contextWindow": 8192,
          "description": "Gemma 3 12B - Google's efficient model",
          "recommendedFor": ["worker"],
          "supportsTools": false,
          "config": {
            "numCtx": 8192,
            "temperature": 0.0,
            "numPredict": -1
          }
        },
        "gemma3:4b": {
          "name": "gemma3:4b",
          "contextWindow": 8192,
          "description": "Gemma 3 4B - fast lightweight model",
          "recommendedFor": ["testing"],
          "supportsTools": false,
          "config": {
            "numCtx": 8192,
            "temperature": 0.0,
            "numPredict": -1
          }
        },
        "phi4-mini:3.8b": {
          "name": "phi4-mini:3.8b",
          "contextWindow": 8192,
          "description": "Phi-4 Mini 3.8B - compact efficient model (NO TOOL SUPPORT)",
          "recommendedFor": ["testing"],
          "supportsTools": false,
          "config": {
            "numCtx": 8192,
            "temperature": 0.0,
            "numPredict": -1
          },
          "warnings": ["This model does not support tool calling - writes pseudocode instead of making actual tool calls"]
        },
        "deepcoder:1.5b": {
          "name": "deepcoder:1.5b",
          "contextWindow": 8192,
          "description": "DeepCoder 1.5B - tiny coding model for testing",
          "recommendedFor": ["testing"],
          "supportsTools": false,
          "config": {
            "numCtx": 8192,
            "temperature": 0.1,
            "numPredict": 1000
          }
        },
        "gpt-oss:20b": {
          "name": "gpt-oss:20b",
          "contextWindow": 131072,
          "description": "GPT-OSS 20B - large open-source model",
          "recommendedFor": ["pm"],
          "supportsTools": true,
          "config": {
            "numCtx": 131072,
            "temperature": 0.0,
            "numPredict": -1
          }
        }
      }
    }
  },
  "agentDefaults": {
    "pm": {
      "provider": "copilot",
      "model": "gpt-4.1",
      "rationale": "PM agent benefits from larger context window for research"
    },
    "worker": {
      "provider": "copilot",
      "model": "gpt-4.1",
      "rationale": "Worker agent uses same model for consistency"
    },
    "qc": {
      "provider": "copilot",
      "model": "gpt-4.1",
      "rationale": "QC agent uses same model for validation"
    }
  },
  "embeddings": {
    "enabled": true,
    "provider": "ollama",
    "model": "nomic-embed-text",
    "dimensions": 768,
    "chunkSize": 400,
    "chunkOverlap": 100
  },
  "features": {
    "pmModelSuggestions": false,
    "vectorEmbeddings": true
  }
}
